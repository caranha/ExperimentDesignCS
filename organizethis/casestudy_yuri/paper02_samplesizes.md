Sample size calculations for the experimental comparison of multiple algorithms on multiple problem instances 

- Abstract
  - Most important part: the summary of the experiment.

- Go to section 5 (Application example - 5.1)
  - Yellow
		- They start by given a description of the problem.
		.. The focus of the paper is not on the problems. A paragraph about it is enough.

 - Green
		- They show the method they are using and why it is a good method for this problem.
		.. We want to know about the method, but again the focus is not on thee method.

 - Blue
		- They show the gap in previous analyses of the algorithm.
		- They introduce the variations of the method that have a considerable effect. 
		.. It is interesting that they connect what is known about the problem with what is uncertain.
		.. They are showing here why their analyses is important - to fill the gap - and how they will do it - verifying if the features commented indeed affect the algorithm.

- Go to section 5.2
 	- Yellow
		- They show the design of the experiment.
		.. See how it relates with the last paragraph from the previous section (blue part).

 - Second yellow
		- They tell us what is that they want to investigate.
		.. This is very important, a very nice and clear design of what the experiments are going to be like.
		.. See how they are interested in investigating the effects of removing each algorithm variation.
		.. Straightforward design - they want to see if each variation affects the performance - so they want to test each variation against the full algorithm - all vs one**, probably using t-test.
		.. Try and do the same in your report.
 		

- Go to section 5.3
	
		- **** They show the parameters for the analise test - power, significance level alpha…
		.. What we learned in class is useful and important. 
		.. Don't forget to add to your work. This will improve the quality of your work.
		.. What else is important for you report?

- Go to section 5.4

 - Green 
		- They present the results in Figure 3 and then comment on these results.
		- Figure 3 (in blue) also presents itself and shows some interpretation of the results.
		.. This is good because we can look at the Figure and find the story behind it, without reading the text again.

 - Pink 
		- Code for reproducibility.
		.. Replication of the results in the base of a good experimentation.

 - Green (Next page)
		- They show the same pattern when introducing Figure 4 as they did for Figure 3.
		.. It is good they repeated the same pattern. We are used to it, and it informative and complete.

 - Green (second)
		- **** Statistical analyses is described in the text and in Figure 5. 
		.. They are doing a pairwise comparisons.
		.. See how they remember us of the significance level alpha. 
		.. Figure 5 shows detailed information - they show 95% the confidence interval (given that the significance level alpha is 5%) and show the mean.
		.. They help the reader get the message.

 - Green (third) 
		- Final results on Table 1 
		- Focus on unexpected results.
		.. T-test, as wee assumed earlier. I recommend in the report to show everything together, not like here. A good section would be in the "experimental parameters" where you define the power, significance level alpha… of your experiment. 
		.. See on the footnote that they explain that the data sums up to follow a normal distribution.

 - Pink (next page)
		.. Unexpected results are important too. This is how we learn new and important things.
		.. They did not find significant differences. They further investigate to understand why - coincidence or not?
 
 - Green
		- Introduces the follow up experiment, based on the simple comments.
		- New description of a smaller, follow up experiment with only the SWP, SWT and SHF variants.

 - Green, pink and purple (next page)
		- a small paragraph covering the same points we discussed now for the follow up experiment.
		.. The extra experiment gives more support to the idea that the SWP, SWT and SHF variants do not affect the algorithm much.



		
	
