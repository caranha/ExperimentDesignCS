
Thank you very much for your comments last week!

# Timezone for the students?
GMT+9 (Japan) 37
GMT+8 (China) 3
GMT-3 (Brazil) 1

# What is Alpha Correction?

I'm happy that almost everyone got this question right.

Here is the "Canonical" Answer:
"Alpha Correction is to adjust the value of the alpha parameter (confidence of
the test) to take into account the increased possibility of type I
error from multiple tests."

Here are some errors:
- "Alpha correct adjusts the probability (p) values" -- no, Alpha correction
adjusts the "alpha" parameter which is used to decide if a test rejects
the null hypothesis or not.

- "The probability of the study rejecting the null hypothesis" -- I think the
student probably understood the concept, but this sentence is incomplete. It
would be better to write "Alpha correction changes the probability of the
study to reject the null hypothesis"

- A few answers were very extensive (4 or 5 sentences). They started correct, but then covered details that were not relevant (such as if the rejection region is on the right or left). Try to focus your answers more!

# What do you do if you find a few big outliers?

Most of the students got this answer correct.
- The first important point is to investigate the outliers. Understand if they are normal results of the experiment, or caused by error. If they are caused by error, you need to understand if the experiment needs to be re-done, or if the error is isolated.
- If the outliers are caused by errors, or by unique circumstances, it may be ok to just remove the data.
- If the outliers are normal result of the experiment, then you need to decide how to treat them. Depending on the number of samples, and the size of the outlier, there are several options: Non-parametric tests, bootstrapping, data conversion, etc.

Some small mistakes:
- "If the outliers are out of the significance interval" -- by definition, outliers are always out of significance interval.
- "I should redo the experiment" -- this can be very expensive. In extreme cases, it might be necessary, but we want to think of other alternatives first.
- "Outliers should be excluded" -- this is one option, but not always the correct option, as described above. If the outliers are a normal part of the experiment, removing them will bias your results.

# Other comments from the Students:

> "Will the Kurskal-Wallis test and Friedman test be discussed in detail in future lectures?"

Maybe we will touch again the Friedman Test in Lecture 8, but I am not sure yet. If you have further questions, please feel free to ask them in the Forum, or the Office Hours.

> Until last week, I was able to catch up with the class because I had knowledge of statistics in my native language (Japanese), but this class is the first time for me to know the contents and it is difficult to understand. I want to review well.

If you have any problems, don't hesitate to ask in the forums!

> Today's topic is so difficult for me. Especially, I can't understand Mann-Whitney U-test. I want to know how this method is used and merit of this.

The Mann-Whitney U test is the equivalent to the T-test for two samples when your data is ordinal. Ordinal data means that it can be ordered, but it is not necessarily possible to do algebra in it. The two samples are the classification of two teams in several tournaments (1st place, 3rd place, 10th place).

The null hypothesis of the Mann-Whitney U test is that the two samples come from the same distribution, so the order of the two samples should be "well shuffled" -- We have about as many high values in the first sample as in the second sample.

To test this hypothesis, we count the "rank" of each observation in the two samples. Under the null hypothesis, this rank-sum should follow a normal distribution, so we can calculate the probability for specific U values.

So this is a way to calculate a random variable that follows a Normal distribution, using an ordinal variable.

> In the design of the second experiment, if i consider some instruments that i have, i can measure Weight, Temperature and Length. What are some other variables that i could consider to measure?

Sorry, can you give more details about your question? I usually answer these questions after removing identifying information.

> How does researchers know what test to use?

By studying a lot of statistics :-) Or by cooperating with a statistician.

> Can choosing test for analysis be automated using a program?

Yes! There are some programs that do automated testing for some specific types of experiments. But this is still a very limited field. If someone could automate this further, it would be appreciated.

Just remember that the choice of statistical test should be done BEFORE the experiment is done, and it is based on the design of the experiment, not on the collected data.

> I think to this point, there are many tests and procedures. It would be cool if we could see some kind of flowchart of how everything link together.

That is true!

> As some other student requested, could you please give more examples during the explanation of a topic?

I have uploaded an example to the manaba, please take a look!

> I will be going to Japan next week. I would like to ask if this course may become offline.

Maybe next year it will be offline.

> Thanks a lot for clarifying the difference between pairing input data instances and pairing benchmark types for sorting algorithms in the last survey!

You're welcome!

> I am considering an experiment on sorting algorithms for my second report, I would like to ask about pairing on two factors.

In general, in this course, we will focus on tests for one factor. In the last lecture, I will talk a bit about tests for two factors (factorial experiment design). But that is a more advanced topic that will not be covered here.

In general, you want to focus on one factor for your analysis, and randomize / block the other factors.
